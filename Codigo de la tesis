######################## Codigo de Tesis ##########################

##################### Librerias #####################

library(npSPC) # Cartas de COntrol No Parametricas
library(plotly) # Graficos
library(readxl) # Leer excel
library(GGally)
library(moments) # skewness
library(e1071) # Kurtosis
library(car) #qqPlot
#library(remotes)
#remotes::install_github('CER-UFBA/npSPC')

#######################################################
# Leer el archivo
ruta_archivo <- file.choose()
Hidroc <- read_excel(ruta_archivo)
names(Hidroc)
##################### Tabla #########################
head(Hidroc)

#######################################################
################## Estadistica descriptiva ############

# Minimo
min(Hidroc$Acum..Pasante)
min(Hidroc$SIZE)
min(log(Hidroc$SIZE))

# Maximo
max(Hidroc$Acum..Pasante)
max(Hidroc$SIZE)
max(log(Hidroc$SIZE))

# Media
mean(Hidroc$Acum..Pasante)
mean(Hidroc$SIZE)
mean(log(Hidroc$SIZE))

# Media Geometrica
media_geometrica <- function(numeros){return(prod(numeros)^(1/length(numeros)))}
media.geo<-function(pesos) {exp(sum(log(pesos))/length(pesos))}
media.geo(Hidroc$SIZE)
media_geometrica(log(Hidroc$SIZE))

# Mediana
median(Hidroc$Acum..Pasante)
median(Hidroc$SIZE)
median(log(Hidroc$SIZE))

# Desviacion estandar
sd(Hidroc$Acum..Pasante)
sd(Hidroc$SIZE)
sd(log(Hidroc$SIZE))

# Rango Intercuartilico
quantile(x = Hidroc$Acum..Pasante, probs = c(0.25, 0.75))
quantile(x = Hidroc$SIZE, probs = c(0.25, 0.75))
quantile(x = log(Hidroc$SIZE), probs = c(0.25, 0.75))

# Skewness

skewness(Hidroc$Acum..Pasante)
skewness(Hidroc$SIZE)
skewness(log(Hidroc$SIZE))

# Kurtosis

kurtosis(Hidroc$Acum..Pasante)
kurtosis(Hidroc$SIZE)
kurtosis(log(Hidroc$SIZE))

# Correlacion de Pearson

cor(Hidroc$Acum..Pasante,Hidroc$SIZE,
    method = "pearson")
cor(Hidroc$Acum..Pasante,log(Hidroc$SIZE),
    method = "pearson")

# Correlación de Spearman

cor(Hidroc$Acum..Pasante,Hidroc$SIZE,
    method = "spearman")

# Correlación de Kendall

cor(Hidroc$Acum..Pasante,Hidroc$SIZE,
    method = "kendall")

##  Figura 5.1

Hidroc$ID=as.factor(Hidroc$ID)
p1=ggplot(Hidroc,aes(x=SIZE,y=Acum..Pasante,group=ID))+
    geom_line(aes(color=ID)) + xlab(
        expression(paste("Granularidad (",mu,"m)"))) + 
    ylab("Acumulado Pasante")+ theme(legend.position="none")

p2=ggplot(Hidroc,aes(x=log(SIZE),y=Acum..Pasante,group=ID))+
    geom_line(aes(color=ID)) + xlab(
        expression(paste("Granularidad [log(",mu,"m)]"))) + 
    ylab("")

cowplot::plot_grid(p1,p2)

######################

GGally::ggpairs(Hidroc[,c("SIZE","Acum..Pasante")])

# Estimacion de parametros de la logistica

############################################################
set.seed(123456)
llike.L3 <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    sigma <- param[3]
    mu <- 100/(1+ exp(-beta0*(SIZE- beta1)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}


## TWO-GROUPS (G1 - 4,5,6,8 and G2 - cc)
a1=Hidroc[Hidroc$ID!=4 & Hidroc$ID!=5 & Hidroc$ID!=6 & Hidroc$ID!=8,]
plot(log(a1$SIZE),a1$Acum..Pasante)

a2=Hidroc[Hidroc$ID==4 | Hidroc$ID==5 | Hidroc$ID==6 | Hidroc$ID==8,]
plot(log(a2$SIZE),a2$Acum..Pasante)

# Usa valores iniciales razonables para mu y sigma
initial3_params <- c(1.543927, 2.353445, 1)
# Optimiza la log-verosimilitud (G1)
result3nolineal <- optim(initial3_params, llike.L3, method = "SANN",
                         y = Hidroc$Acum..Pasante, SIZE = log(Hidroc$SIZE))
print(result3nolineal)
coeficientes3 <- result3nolineal$par
coeficientes3


# Figura 5.2
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad")
indexNO <- seq(min(log(Hidroc$SIZE)),max(log(Hidroc$SIZE)),length.out=100)
yhatNO <- 100/(1+exp(-coeficientes3[1]*(indexNO- coeficientes3[2])))
lines(indexNO, yhatNO, col = "red", lwd = 2)
coeficientes3

# Calculo de residuales
yhat <- 100/(1+exp(-coeficientes3[1]*(log(Hidroc$SIZE)- coeficientes3[2])))
plot(log(Hidroc$SIZE),yhat,ylab="Acumulado Pasante",xlab="Granularidad")



Hidroc$residualdeloptim <- Hidroc$Acum..Pasante - yhat
# Promedio
mean(Hidroc$residualdeloptim)
# Skewness
skewness(Hidroc$residualdeloptim)
# Durbin-Watson
residuals <- Hidroc$residualdeloptim
n <- length(residuals)
dw <- sum((residuals[-1] - residuals[-n])^2) / sum(residuals^2)
print(dw)
# QQ-plot
library(car)
qqPlot(Hidroc$residualdeloptim)


# Shapiro-Wilk
shapiro.test(Hidroc$residualdeloptim)

##########################################
# Cleaning Dataset
ss=Hidroc[Hidroc$SIZE>0.7 & Hidroc$SIZE<631,]


require(ggplot2)
p11=ggplot(ss, aes(x=residualdeloptim)) + geom_histogram() + coord_flip() + 
    scale_y_reverse()  + theme(
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

p12=ggplot(ss,aes(x=as.factor(SIZE),y=residualdeloptim)) + 
    geom_violin(alpha=0.6) + xlab("Sample (unit)") + 
    ylab("Diff(Observed Sample, Estimated Model)") +
    stat_summary(fun = "median",col="red")+ 
    stat_summary(fun = "mean", col="blue")+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

cowplot::plot_grid(p11,p12,rel_heights = c(2,1),
                   rel_widths = c(1, 3))




########################## Interpolacion #############################


# Lineal
# Logaritmica
# Realizadas en el excel


# Directa del modelo
d50 <- -log(100/50-1)/1.552856 + 2.352640
exp(d50)

d80 <- -log(100/80-1)/1.552856 + 2.352640
exp(d80)



#################### Residual del Modelo via CEP ####################

library(data.table)
setDT(ss)
DB1=dcast(ss, SIZE ~ ID, value.var = "residualdeloptim")[,-1]

##--PARAMETRIC SPC--
require(qcc)
qcc.options(bg.margin = "white")

# Shewhart's (X-Bar and Range)
XbarChart = qcc(DB1, type = "xbar", center=0)
RChart = qcc(DB1, type = "R")
# CuSUM
CuSumChart <- cusum(DB1)
summary(CuSumChart)
# EWMA
EWMAChart <- ewma(DB1, lambda=0.2, nsigmas=3)
summary(EWMAChart)

##--NONPARAMETRIC SPC--
library(plotly)
require(npSPC)
shewhart_sr(DB1, group_by_col = TRUE, mu0 = 0, exact = TRUE)
cusum_sn(DB1, group_by_col = TRUE, 
         k = shapiro.test(as.matrix(DB1))$statistic/2, h = 50)

ewma_sn(DB1, group_by_col = TRUE, 
        lambda = shapiro.test(as.matrix(DB1))$statistic/2, L = 2.472)

######################## Ggplot #######################

########################################################################
ss=Hidroc[Hidroc$SIZE<75,]
names(ss)

ggplot(ss,aes(y=Acum..Pasante,x=SIZE,color=as.factor(ID) )) + 
    geom_point() + geom_smooth(method="gam")

###########################Tabla 5.3 ##########################
# ID 1
HidrocID1 <-  Hidroc %>% filter(ID == "1")
HidrocID2 <-  Hidroc %>% filter(ID == "2")
HidrocID3 <-  Hidroc %>% filter(ID == "3")
HidrocID4 <-  Hidroc %>% filter(ID == "4")
HidrocID5 <-  Hidroc %>% filter(ID == "5")
HidrocID6 <-  Hidroc %>% filter(ID == "6")
HidrocID7 <-  Hidroc %>% filter(ID == "7")
HidrocID8 <-  Hidroc %>% filter(ID == "8")
HidrocID9 <-  Hidroc %>% filter(ID == "9")
HidrocID10 <-  Hidroc %>% filter(ID == "10")
HidrocID11 <-  Hidroc %>% filter(ID == "11")
HidrocID12 <-  Hidroc %>% filter(ID == "12")
HidrocID13 <-  Hidroc %>% filter(ID == "13")
HidrocID14 <-  Hidroc %>% filter(ID == "14")
HidrocID15 <-  Hidroc %>% filter(ID == "15")

initialparams <- c(1.543927, 2.353445, 1)
# Optimiza la log-verosimilitud (ID1)
set.seed(0)
resultnolinealID1 <- optim(initialparams, llike.L3, method = "SANN",
                         y = HidrocID1$Acum..Pasante, SIZE = log(HidrocID1$SIZE))


resultnolinealID1$par
d50ID1 <- -log(100/50-1)/resultnolinealID1$par[1] + resultnolinealID1$par[2]
exp(d50ID1)

xid1 <- 6
YID1 <- 100/(1+exp(-resultnolinealID1$par[1]*(xid1 -resultnolinealID1$par[2])))
YID1

# Optimiza la log-verosimilitud (ID2)
set.seed(0)
resultnolinealID2 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID2$Acum..Pasante, SIZE = log(HidrocID2$SIZE))


resultnolinealID2$par
d50ID2 <- -log(100/50-1)/resultnolinealID2$par[1] + resultnolinealID2$par[2]
exp(d50ID2)

xid2 <- 6
YID2 <- 100/(1+exp(-resultnolinealID2$par[1]*(xid2 -resultnolinealID2$par[2])))
YID2

# Optimiza la log-verosimilitud (ID3)
set.seed(0)
resultnolinealID3 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID3$Acum..Pasante, SIZE = log(HidrocID3$SIZE))


resultnolinealID3$par
d50ID3 <- -log(100/50-1)/resultnolinealID3$par[1] + resultnolinealID3$par[2]
exp(d50ID3)

xid3 <- 6
YID3 <- 100/(1+exp(-resultnolinealID3$par[1]*(xid3 -resultnolinealID3$par[2])))
YID3

# Optimiza la log-verosimilitud (ID4)
set.seed(0)
resultnolinealID4 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID4$Acum..Pasante, SIZE = log(HidrocID4$SIZE))


resultnolinealID4$par
d50ID4 <- -log(100/50-1)/resultnolinealID4$par[1] + resultnolinealID4$par[2]
exp(d50ID4)

xid4 <- 6
YID4 <- 100/(1+exp(-resultnolinealID4$par[1]*(xid2 -resultnolinealID4$par[2])))
YID4
# Optimiza la log-verosimilitud (ID5)
set.seed(0)
resultnolinealID5 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID5$Acum..Pasante, SIZE = log(HidrocID5$SIZE))


resultnolinealID5$par
d50ID5 <- -log(100/50-1)/resultnolinealID5$par[1] + resultnolinealID5$par[2]
exp(d50ID5)

xid5 <- 6
YID5 <- 100/(1+exp(-resultnolinealID5$par[1]*(xid2 -resultnolinealID5$par[2])))
YID5
# Optimiza la log-verosimilitud (ID6)
set.seed(0)
resultnolinealID6 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID6$Acum..Pasante, SIZE = log(HidrocID6$SIZE))


resultnolinealID6$par
d50ID6 <- -log(100/50-1)/resultnolinealID6$par[1] + resultnolinealID6$par[2]
exp(d50ID6)

xid6 <- 6
YID6 <- 100/(1+exp(-resultnolinealID6$par[1]*(xid6 -resultnolinealID6$par[2])))
YID6
# Optimiza la log-verosimilitud (ID7)
set.seed(0)
resultnolinealID7 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID7$Acum..Pasante, SIZE = log(HidrocID7$SIZE))


resultnolinealID7$par
d50ID7 <- -log(100/50-1)/resultnolinealID7$par[1] + resultnolinealID7$par[2]
exp(d50ID7)

xid7 <- 6
YID7 <- 100/(1+exp(-resultnolinealID7$par[1]*(xid7 -resultnolinealID7$par[2])))
YID7
# Optimiza la log-verosimilitud (ID8)
set.seed(0)
resultnolinealID8 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID8$Acum..Pasante, SIZE = log(HidrocID8$SIZE))


resultnolinealID8$par
d50ID8 <- -log(100/50-1)/resultnolinealID8$par[1] + resultnolinealID8$par[2]
exp(d50ID8)

xid8 <- 6
YID8 <- 100/(1+exp(-resultnolinealID8$par[1]*(xid8 -resultnolinealID8$par[2])))
YID8
# Optimiza la log-verosimilitud (ID9)
set.seed(0)
resultnolinealID9 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID9$Acum..Pasante, SIZE = log(HidrocID9$SIZE))


resultnolinealID9$par
d50ID9 <- -log(100/50-1)/resultnolinealID9$par[1] + resultnolinealID9$par[2]
exp(d50ID9)

xid9 <- 6
YID9 <- 100/(1+exp(-resultnolinealID9$par[1]*(xid9 -resultnolinealID9$par[2])))
YID9
# Optimiza la log-verosimilitud (ID10)
set.seed(0)
resultnolinealID10 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID10$Acum..Pasante, SIZE = log(HidrocID10$SIZE))


resultnolinealID10$par
d50ID10 <- -log(100/50-1)/resultnolinealID10$par[1] + resultnolinealID10$par[2]
exp(d50ID10)

xid10 <- 6
YID10 <- 100/(1+exp(-resultnolinealID10$par[1]*(xid10 -resultnolinealID10$par[2])))
YID10
# Optimiza la log-verosimilitud (ID11)
set.seed(0)
resultnolinealID11 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID11$Acum..Pasante, SIZE = log(HidrocID11$SIZE))


resultnolinealID11$par
d50ID11 <- -log(100/50-1)/resultnolinealID11$par[1] + resultnolinealID11$par[2]
exp(d50ID11)

xid11 <- 6
YID11 <- 100/(1+exp(-resultnolinealID11$par[1]*(xid11 -resultnolinealID11$par[2])))
YID11
# Optimiza la log-verosimilitud (ID12)
set.seed(0)
resultnolinealID12 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID12$Acum..Pasante, SIZE = log(HidrocID12$SIZE))


resultnolinealID12$par
d50ID12 <- -log(100/50-1)/resultnolinealID12$par[1] + resultnolinealID12$par[2]
exp(d50ID12)

xid12 <- 6
YID12 <- 100/(1+exp(-resultnolinealID12$par[1]*(xid12 -resultnolinealID12$par[2])))
YID12
# Optimiza la log-verosimilitud (ID13)
set.seed(0)
resultnolinealID13 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID13$Acum..Pasante, SIZE = log(HidrocID13$SIZE))


resultnolinealID13$par
d50ID13 <- -log(100/50-1)/resultnolinealID13$par[1] + resultnolinealID13$par[2]
exp(d50ID13)

xid13 <- 6
YID13 <- 100/(1+exp(-resultnolinealID13$par[1]*(xid13 -resultnolinealID13$par[2])))
YID13
# Optimiza la log-verosimilitud (ID14)
set.seed(0)
resultnolinealID14 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID14$Acum..Pasante, SIZE = log(HidrocID14$SIZE))


resultnolinealID14$par
d50ID14 <- -log(100/50-1)/resultnolinealID14$par[1] + resultnolinealID14$par[2]
exp(d50ID14)

xid14 <- 6
YID14 <- 100/(1+exp(-resultnolinealID14$par[1]*(xid14 -resultnolinealID14$par[2])))
YID14
# Optimiza la log-verosimilitud (ID15)
set.seed(0)
resultnolinealID15 <- optim(initialparams, llike.L3, method = "SANN",
                           y = HidrocID15$Acum..Pasante, SIZE = log(HidrocID15$SIZE))


resultnolinealID15$par
d50ID15 <- -log(100/50-1)/resultnolinealID15$par[1] + resultnolinealID15$par[2]
exp(d50ID15)

xid15 <- 6
YID15 <- 100/(1+exp(-resultnolinealID15$par[1]*(xid15 -resultnolinealID15$par[2])))
YID15





################################################################

ss %>% filter(ID!=1) %>% 
    ggplot(aes(y=Acum..Pasante,x=SIZE,color=as.factor(PRESION) )) + 
    geom_point() + geom_smooth(method="gam")

ss %>% filter(ID!=1) %>% 
    ggplot(aes(y=Acum..Pasante,x=SIZE,color=as.factor(APEX) )) + 
    geom_point() + geom_smooth(method="gam")

ss %>% filter(ID!=1) %>% 
    ggplot(aes(y=Acum..Pasante,x=SIZE,color=as.factor(SOLIDO) )) + 
    geom_point() + geom_smooth(method="gam")


library(tidyverse)
ss_new <- ss %>% mutate(presion_tipo= case_when(PRESION==2 ~'A', 
                                                PRESION==3 ~'A',
                                                PRESION==4.4 ~'A',
                                                PRESION==1.6 ~'B',
                                                PRESION==7.6 ~'B'
)) 


ss_new %>% filter(ID!=1) %>% 
    ggplot(aes(y=Acum..Pasante,x=SIZE,color=as.factor(presion_tipo) )) + 
    geom_point() 

############################### ANOVA ###########################

ss_new$Acum..Pasante[ss_new$Acum..Pasante==0]=0.0001
ss_new$logit=log(ss_new$Acum..Pasante/100)-log(1-(ss_new$Acum..Pasante/100))

# Plot
y=log((ss$Acum..Pasante)/(100-ss$Acum..Pasante))
plot(log(ss$SIZE),y )

ss_new$APEX=as.factor(ss_new$APEX)
ss_new$SOLIDO=as.factor(ss_new$SOLIDO)

# modelo lineal
fit <- lm(logit ~ log(SIZE) * presion_tipo + SOLIDO + APEX, data=ss_new)
summary(fit)
# Anova

fit=lm(logit ~ log(SIZE) + presion_tipo + SOLIDO + APEX, data=ss_new)
summary(aov(fit))


############################## Residuo logistica #####################

plot(Hidroc$residualdeloptim, type = "line")

acf(Hidroc$residualdeloptim)
pacf(Hidroc$residualdeloptim)

############################ Agregar filtro ARIMA ###################

library(forecast)

auto.arima(Hidroc$residualdeloptim)

plot(residuals(auto.arima(Hidroc$residualdeloptim)))

pacf(residuals(auto.arima(Hidroc$residualdeloptim)))

# Revisar

modelo <- auto.arima(Hidroc$residualdeloptim)
residuos <- residuals(modelo)

# Crear el histograma
hist(residuos, breaks=1000, probability=TRUE, main="Histograma de Residuos", xlab="Residuos", xlim = c(-5,2.5))

# Generar la secuencia para la curva de densidad
x <- seq(min(residuos), max(residuos), length=100)

# Calcular la densidad normal
y <- dnorm(x, mean=mean(residuos), sd=sd(residuos))

# Agregar la línea de densidad al histograma
lines(x, y, col="red", lwd=2)

################################## 17 Modelos ########################

#gaudin -schuhmann

set.seed(123456)
llike.gaudin_schuhmann <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    sigma <- param[3]
    mu <-  100*(SIZE/beta0)^beta1
    #    mu <- 100*(SIZE/beta0)^beta1
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_gaudin_schuhmann <- c(15, 1,1)
# Optimiza la log-verosimilitud (G1)
result_gaudin_schuhmann <- optim(initial_gaudin_schuhmann, llike.gaudin_schuhmann, method = "SANN",
                                 y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_gaudin_schuhmann)
coeficientes <- result_gaudin_schuhmann$par


# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Gaudin-Schuhmann")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=1000)
yhat_gaudin_schuhmann <- 100*(indexNO/result_gaudin_schuhmann$par[1])^result_gaudin_schuhmann$par[2]
lines(log(indexNO), yhat_gaudin_schuhmann, col = "red", lwd = 2)

#verosimilitud
llike.gaudin_schuhmann(result_gaudin_schuhmann$par,y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)

result_gaudin_schuhmann$value


####### Rossin rammler
set.seed(123456)
llike.rossin_rammler <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    sigma <- param[3]
    mu <- 100*(1-exp(-(SIZE/beta0)^beta1))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}

# Usa valores iniciales razonables para mu y sigma
initial_rossin_rammler <- c(10, 20, 2)
# Optimiza la log-verosimilitud (G1)
result_rossin_rammler <- optim(initial_rossin_rammler, llike.rossin_rammler, method = "SANN",
                               y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_rossin_rammler)
coeficientes <- result_rossin_rammler$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Rossin-Rammler")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=1000)
yhat_rossin_rammler <- 100*(1-exp(-(indexNO/result_rossin_rammler$par[1])^result_rossin_rammler$par[2]))
lines(log(indexNO), yhat_rossin_rammler, col = "red", lwd = 2)


#verosimilitud
llike.rossin_rammler(result_rossin_rammler$par, y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)

result_rossin_rammler$value

#modelo  Swebrec
set.seed(123456)
llike_swebrec <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    sigma <- param[3]
    mu <-  100/(1+(log(max(SIZE)/SIZE)/log(max(SIZE)/beta1))^beta0)
    #    mu <- 100*(SIZE/beta0)^beta1
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_swebrec <- c(15, 1,1)
# Optimiza la log-verosimilitud (G1)
result_swebrec <- optim(initial_swebrec, llike_swebrec, method = "SANN",
                        y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_swebrec)
coeficientes3 <- result_swebrec$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Swebrec")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=1000)
#yhatNO <- 100*(indexNO/coeficientes3[1])^coeficientes3[2]
yhat_swebrec <- 100/(1+(log(max(indexNO)/indexNO)/log(max(indexNO)/result_swebrec$par[2]))^result_swebrec$par[1])
lines(log(indexNO), yhat_swebrec, col = "red", lwd = 2)


#verosimilitud
llike_swebrec(result_swebrec$par,y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
result_swebrec$value

#gompertz
set.seed(123456)
llike_Lgompertz <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    sigma <- param[3]
    mu <-  100*exp(-exp(-beta0*(SIZE-beta1)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_Lgompertz <- c(0, 9, 1)
# Optimiza la log-verosimilitud (G1)
result_Lgompertz <- optim(initial_Lgompertz, llike_Lgompertz, method = "SANN",
                          y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_Lgompertz)
coeficientes3 <- result_Lgompertz$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "gompertz")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=1000)

yhatNO_lgompertz <- 100*exp(-exp(-result_Lgompertz$par[1]*(indexNO-result_Lgompertz$par[2])))
lines(log(indexNO), yhatNO_lgompertz, col = "red", lwd = 2)

# verosimilitud
llike_Lgompertz(result_Lgompertz$par,y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
result_Lgompertz$value

############weibull


plot(Hidroc$SIZE,Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "gompertz",xlim = c(0,5), ylim=c(0,20))
# para obtener el p0.002
set.seed(123456)
llike.Lweibull <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- 100-(100-beta0)*exp(-(beta1*SIZE)^beta2)
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_Lweibull <- c(15, 1, 1, 7)
# Optimiza la log-verosimilitud (G1)
result_Lweibull <- optim(initial_Lweibull, llike.Lweibull, method = "SANN",
                         y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_Lweibull)
coeficientes3 <- result_Lweibull$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "weibull")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
#yhatNO <- 100*(indexNO/coeficientes3[1])^coeficientes3[2]
yhatNO_Lweibull <- 100-(100-result_Lweibull$par[1])*exp(-(result_Lweibull$par[2]*indexNO)^result_Lweibull$par[3])
lines(log(indexNO), yhatNO_Lweibull, col = "red", lwd = 2)


# verosimilitud

result_Lweibull$value

# Modelo bass
set.seed(123456)
llike.bass <- function(param, y, SIZE) {
    beta0 <- 100
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- beta0*((1-exp(-(beta1+beta2)*SIZE))/(1+ beta2/beta1*exp(-(beta1+beta2)*SIZE)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_bass <- c(100, 0, 0, 1)
# Optimiza la log-verosimilitud (G1)
result_bass <- optim(initial_bass, llike.bass, method = "SANN",
                     y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_bass)
coeficientes3 <- result_bass$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Bass")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_bass <- result_bass$par[1]*((1-exp(-(result_bass$par[2]+result_bass$par[3])*indexNO))/(1+ result_bass$par[3]/result_bass$par[2]*exp(-(result_bass$par[2]+result_bass$par[3])*indexNO)))
lines(log(indexNO), yhatNO_bass, col = "red", lwd = 2)



line_data <- data.frame(indexNO = indexNO, yhatNO_bass = yhatNO_bass)

# Crear el gráfico con ggplot2
ggplot(Hidroc, aes(x = log(SIZE), y = Acum..Pasante)) +
    geom_point() +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_bass), color = "red", size = 1) +
    labs(x = "Granularidad", y = "Acumulado Pasante", title = "Bass") +
    theme_minimal()

# verosimilitud

result_bass$value


#vector x
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)

#vectores de y
yhatNO_Lweibull <- 100-(100-result_Lweibull$par[1])*exp(-(result_Lweibull$par[2]*indexNO)^result_Lweibull$par[3])
yhatNO_lgompertz <- 100*exp(-exp(-result_Lgompertz$par[1]*(indexNO-result_Lgompertz$par[2])))
yhat_swebrec <- 100/(1+(log(max(indexNO)/indexNO)/log(max(indexNO)/result_swebrec$par[2]))^result_swebrec$par[1])
yhat_rossin_rammler <- 100*(1-exp(-(indexNO/result_rossin_rammler$par[1])^result_rossin_rammler$par[2]))
yhat_gaudin_schuhmann <- 100*(indexNO/result_gaudin_schuhmann$par[1])^result_gaudin_schuhmann$par[2]


# grafico
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante", xlab = expression( paste("Granulometría [log(",mu,"m)]") ), main = "Ajuste de modelos", ylim = c(0,101))
lines(log(indexNO), yhatNO_Lweibull, col = "red", lwd = 3)
lines(log(indexNO), yhatNO_lgompertz, col = "blue", lwd = 3)
lines(log(indexNO), yhat_swebrec, col = "green", lwd = 3)
lines(log(indexNO), yhat_gaudin_schuhmann, col = "yellow", lwd = 3)
lines(log(indexNO), yhat_rossin_rammler, col = "purple", lwd = 3)
lines(log(indexNO), yhatNO_bass, col = "gray", lwd = 3)

legend("bottomright", 
       legend = c("Modelo Weibull", "Modelo Gompertz", "Modelo Swebrec", "Modelo Gaudin-Schuhmann", "Modelo Rossin-Rammler", "Modelo Bass"),
       col = c("red", "blue", "green", "yellow", "purple", "gray"),
       lwd = 3,
       bty = "n")


line_data1 <- data.frame(indexNO = indexNO, yhatNO_bass = yhatNO_bass)
line_data2 <- data.frame(indexNO = indexNO, yhatNO_bass = yhatNO_bass)

lines(log(indexNO), yhatNO_Lweibull, col = "red", lwd = 3)
lines(log(indexNO), yhatNO_lgompertz, col = "blue", lwd = 3)
lines(log(indexNO), yhat_swebrec, col = "green", lwd = 3)
lines(log(indexNO), yhat_gaudin_schuhmann, col = "yellow", lwd = 3)
lines(log(indexNO), yhat_rossin_rammler, col = "purple", lwd = 3)
lines(log(indexNO), yhatNO_bass, col = "gray", lwd = 3)



# Crear el gráfico con ggplot2
ggplot(Hidroc, aes(x = log(SIZE), y = Acum..Pasante)) +
    geom_point(aes(color = factor("Datos", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass")))) +
    geom_line(data = line_data1, aes(x = log(indexNO), y = yhatNO_Lweibull, color = factor("Weibull", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_lgompertz, color = factor("Gompertz", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhat_swebrec, color = factor("Swebrec", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhat_gaudin_schuhmann, color = factor("Gaudin Schuhmann", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhat_rossin_rammler, color = factor("Rosin Rammler", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_bass, color = factor("Bass", levels = c("Datos", "Weibull", "Gompertz", "Swebrec", "Gaudin Schuhmann", "Rosin Rammler", "Bass"))), size = 1.5) +
    
    labs(x = "Granulometría", y = "Acumulado Pasante", title = "Ajuste de los modelos") +
    ylim(0, 100) +
    scale_color_manual(name = "Leyenda",
                       values = c("Datos" = "black",
                                  "Bass" = "gray",
                                  "Gaudin Schuhmann" = "yellow",
                                  "Gompertz" = "blue",
                                  "Rosin Rammler" = "purple",
                                  "Swebrec" = "green",
                                  "Weibull" = "red")) +
    theme_minimal()


######################### Richards
set.seed(123456)
llike.richards <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- 100*(1+(beta0-1)*(exp(-beta1*(SIZE-beta2))))^(1/(1-beta0))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_richards <- c(15, 1, 10, 7)
# Optimiza la log-verosimilitud (G1)
result_richards <- optim(initial_richards, llike.richards, method = "SANN",
                         y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_richards)
coeficientes3 <- result_richards$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "richards")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)

yhatNO_richards <- 100*(1+(result_richards$par[1]-1)*(exp(-result_richards$par[2]*(indexNO-result_richards$par[3]))))^(1/(1-result_richards$par[1]))
lines(log(indexNO), yhatNO_richards, col = "red", lwd = 2)

# verosimilitud
result_richards$value

################### Morgan et al
set.seed(123456)
llike.morganetal <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- 100-((100-beta0)/(1+(beta1*SIZE)^beta2))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_morganetal <- c(15, 1, 1, 7)
# Optimiza la log-verosimilitud (G1)
result_morganetal <- optim(initial_morganetal, llike.morganetal, method = "SANN",
                           y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_morganetal)
coeficientes3 <- result_morganetal$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "weibull")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)

yhatNO_morganetal <- 100-((100-result_morganetal$par[1])/(1+(result_morganetal$par[2]*indexNO)^result_morganetal$par[3]))
lines(log(indexNO), yhatNO_morganetal, col = "red", lwd = 2)

# verosimilitud
result_morganetal$value


######################### Havercamp
set.seed(123456)
llike.havercamp <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- 100/(1+(beta0/SIZE)^beta1)^beta2
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_havercamp <- c(15, 1, 1, 7)
# Optimiza la log-verosimilitud (G1)
result_havercamp <- optim(initial_havercamp, llike.havercamp, method = "SANN",
                          y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_havercamp)
coeficientes3 <- result_havercamp$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "havercamp")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)

yhatNO_havercamp <- 100/(1+(result_havercamp$par[1]/indexNO)^result_havercamp$par[2])^result_havercamp$par[3]
lines(log(indexNO), yhatNO_havercamp, col = "red", lwd = 2)

# verosimilitud
result_havercamp$value



######################### fredlund 
set.seed(123456)
llike.fredlund <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    first_part <- (100/(log(exp(1)+(((beta0/SIZE)^beta1)^beta2))))
    second_part <- (1-(log(1+min(SIZE)/SIZE)/log(1+min(SIZE)/0.00001))^7)
    mu <- first_part * second_part
    
    #    mu <- (100/(log(exp(1)+(((beta0/SIZE)^beta1)^beta2))))(1-(log(1+min(SIZE)/SIZE)/log(1+min(SIZE)/SIZE))^7)
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_fredlund <- c(15, 1, 1, 7)
# Optimiza la log-verosimilitud (G1)
result_fredlund <- optim(initial_fredlund, llike.fredlund, method = "SANN",
                         y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_fredlund)
coeficientes3 <- result_fredlund$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "fredlund")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)

first_part <- (100/(log(exp(1)+(((result_fredlund$par[1]/indexNO)^result_fredlund$par[2])^result_fredlund$par[3]))))
second_part <- (1-(log(1+min(indexNO)/indexNO)/log(1+min(indexNO)/0.00001))^7)
yhatNO_fredlund <- first_part * second_part
lines(log(indexNO), yhatNO_fredlund, col = "red", lwd = 2)

# verosimilitud
result_fredlund$value

######################## skaggs
set.seed(123456)
llike.skaggs <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- 100/(1+(100/beta0-1)*exp(-beta1*SIZE^beta2))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_skaggs <- c(15, 1, 1, 7)
# Optimiza la log-verosimilitud (G1)
result_skaggs <- optim(initial_skaggs, llike.skaggs, method = "SANN",
                       y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_skaggs)
coeficientes3 <- result_skaggs$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "skaggs")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_skaggs <- 100/(1+(100/result_skaggs$par[1]-1)*exp(-result_skaggs$par[2]*indexNO^result_skaggs$par[3]))
lines(log(indexNO), yhatNO_skaggs, col = "red", lwd = 2)

# verosimilitud
result_skaggs$value


# plot de otros 5 modelos


plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab = expression( paste("Granulometría [log(",mu,"m)]")) , main = "Ajuste de los modelos")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
lines(log(indexNO), yhatNO_fredlund, col = "red", lwd = 3)
lines(log(indexNO), yhatNO_havercamp, col = "blue", lwd = 3)
lines(log(indexNO), yhatNO_morganetal, col = "green", lwd = 3)
lines(log(indexNO), yhatNO_richards, col = "purple", lwd = 3)
lines(log(indexNO), yhatNO_skaggs, col = "black", lwd = 3)

legend("bottomright",
       legend = c("Modelo Fredlund", "Modelo Havercamp", "Modelo Morgan et al.", "Modelo Richards", "Modelo Skaggs"),
       col = c("red", "blue", "green", "purple", "black"),
       lwd = 3,
       bty = "n")

######################CON GGPLOT

ggplot(Hidroc, aes(x = log(SIZE), y = Acum..Pasante)) +
    geom_point(aes(color = factor("Datos", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs")))) +
    geom_line(data = line_data1, aes(x = log(indexNO), y = yhatNO_fredlund, color = factor("Fredlund", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_havercamp, color = factor("Havercamp", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_morganetal, color = factor("Morgan et al", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_richards, color = factor("Richards", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs"))), size = 1.5) +
    geom_line(data = line_data2, aes(x = log(indexNO), y = yhatNO_skaggs, color = factor("Skaggs", levels = c("Datos", "Fredlund", "Havercamp", "Morgan et al", "Richards", "Skaggs"))), size = 1.5) +
    
    labs(x = "Granulometría", y = "Acumulado Pasante", title = "Ajuste de los modelos") +
    ylim(0, 100) +
    scale_color_manual(name = "Leyenda",
                       values = c("Datos" = "black",
                                  "Fredlund" = "yellow",
                                  "Havercamp" = "blue",
                                  "Morgan et al" = "purple",
                                  "Richards" = "green",
                                  "Skaggs" = "red")) +
    theme_minimal()


######################## lima
set.seed(123456)
llike.lima <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- beta0 + (100-beta0)/(1+(beta1/SIZE)^beta2)^(1-1/beta2)
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_lima <- c(0, 0, 1, 1)
# Optimiza la log-verosimilitud (G1)
result_lima <- optim(initial_lima, llike.lima, method = "SANN",
                     y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_lima)
coeficientes3 <- result_lima$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "lima")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_lima <- result_lima$par[1] + (100-result_lima$par[1])/(1+(result_lima$par[2]/indexNO)^result_lima$par[3])^(1-1/result_lima$par[3])
lines(log(indexNO), yhatNO_lima, col = "red", lwd = 2)

max(yhatNO_lima)
# verosimilitud
result_lima$value


########## logistica
set.seed(123456)
llike.logistica <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    #beta2 <- 100
    sigma <- param[4]
    mu <- 100/(1+ exp(-beta0*(SIZE- beta1)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
initial3_params <- c(0, 0, 1)
# Optimiza la log-verosimilitud (G1)
result_logistica <- optim(initial3_params, llike.L3, method = "L-BFGS-B",
                          y = Hidroc$Acum..Pasante, SIZE = log(Hidroc$SIZE))
print(result_logistica)
coeficientes3 <- result_logistica$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad",main = "logistica")
indexNO <- seq(min(log(Hidroc$SIZE)),max(log(Hidroc$SIZE)),length.out=5000)
yhatNO_logistica <- 100/(1+exp(-result_logistica$par[1]*(indexNO- result_logistica$par[2])))
lines(indexNO, yhatNO_logistica, col = "red", lwd = 2)

# verosimilitud
result_logistica$value


# monomolecular
set.seed(123456)
llike.monomolecular <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- beta0*(1-(((beta0-beta1)/beta0)*exp(-beta2*SIZE)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_monomolecular <- c(100, 0, 0, 7)
# Optimiza la log-verosimilitud (G1)
result_monomolecular <- optim(initial_monomolecular, llike.monomolecular, method = "SANN",
                              y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_monomolecular)
coeficientes3 <- result_monomolecular$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Monomolecular")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_monomolecular <- result_monomolecular$par[1]*(1-(((result_monomolecular$par[1]-result_monomolecular$par[2])/result_monomolecular$par[1])*exp(-result_monomolecular$par[3]*indexNO)))
lines(log(indexNO), yhatNO_monomolecular, col = "red", lwd = 2)

# verosimilitud
result_monomolecular$value



# Brody
set.seed(123456)
llike.brody <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- beta0*(1-(((beta0-beta1)/beta0)*exp(-beta2*SIZE)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_brody <- c(100, 0, 0, 7)
# Optimiza la log-verosimilitud (G1)
result_brody <- optim(initial_brody, llike.brody, method = "SANN",
                      y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_brody)
coeficientes3 <- result_brody$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Brody")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_brody <- result_monomolecular$par[1]*(1-(((result_monomolecular$par[1]-result_monomolecular$par[2])/result_monomolecular$par[1])*exp(-result_monomolecular$par[3]*indexNO)))
lines(log(indexNO), yhatNO_brody, col = "red", lwd = 2)

# verosimilitud
result_brody$value

# Bertalanffy
set.seed(123456)
llike.bertalanffy <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    sigma <- param[4]
    mu <- beta0*(1- exp(-beta1*(SIZE-beta2)))
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_bertalanffy <- c(100, 0, 0, 7)
# Optimiza la log-verosimilitud (G1)
result_bertalanffy <- optim(initial_bertalanffy, llike.bertalanffy, method = "SANN",
                            y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_bertalanffy)
coeficientes3 <- result_bertalanffy$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granulometría", main = "Bertalanffy")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_bertalanffy <- result_bertalanffy$par[1]*(1- exp(-result_bertalanffy$par[2]*(indexNO-result_bertalanffy$par[3])))
lines(log(indexNO), yhatNO_bertalanffy, col = "red", lwd = 2)

# Cargar librerías necesarias
library(ggplot2)

# Suponiendo que 'Hidroc' es tu dataframe
# Calcular los valores ajustados usando el modelo de Bertalanffy
indexNO <- seq(min(Hidroc$SIZE), max(Hidroc$SIZE), length.out = 5000)
yhatNO_bertalanffy <- 98.35030894 * (1 - exp(-0.06821427 * (indexNO - 0.70781219)))

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granulometría", main = "Bertalanffy")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_bertalanffy <- result_bertalanffy$par[1]*(1- exp(-result_bertalanffy$par[2]*(indexNO-result_bertalanffy$par[3])))
lines(log(indexNO), yhatNO_bertalanffy, col = "red", lwd = 2)


# Hill
# link del hill
# http://article.sapub.org/10.5923.j.statistics.20201006.01.html#:~:text=Hill%20model%20is%20an%20S,it%20is%20used%20in%20prediction.
set.seed(123456)
llike.hill <- function(param, y, SIZE) {
    beta0 <- param[1]
    beta1 <- param[2]
    beta2 <- param[3]
    beta3 <- param[4]
    sigma <- param[5]
    mu <- beta0 + beta1*(SIZE/(beta2+SIZE))^beta3 
    n <- length(y)  # Define n como la longitud del vector de datos
    ll = -(n/2) * log(2 * pi * sigma^2) - (1 / (2 * sigma^2)) * sum((y - mu)^2)
    return(-ll)  # Negamos la log-verosimilitud porque optim minimiza
}
# Usa valores iniciales razonables para mu y sigma
initial_hill <- c(10, 1, 0, 0, 7)
# Optimiza la log-verosimilitud (G1)
result_hill <- optim(initial_hill, llike.hill, method = "SANN",
                     y = Hidroc$Acum..Pasante, SIZE = Hidroc$SIZE)
print(result_hill)
coeficientes3 <- result_hill$par

# Calcula las funciones
plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante",xlab="Granularidad", main = "Hill")
indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
yhatNO_hill <- result_hill$par[1] + result_hill$par[2]*(indexNO/(result_hill$par[3]+indexNO))^result_hill$par[4]
lines(log(indexNO), yhatNO_hill, col = "red", lwd = 2)

# verosimilitud
result_hill$value












plot(log(Hidroc$SIZE),Hidroc$Acum..Pasante,ylab="Acumulado Pasante", xlab = expression( paste("Granulometría [log(",mu,"m)]")), main = "Ajuste de los modelos")

indexNO <- seq(min(Hidroc$SIZE),max(Hidroc$SIZE),length.out=5000)
lines(log(indexNO), yhatNO_hill, col = "red", lwd = 3)
lines(log(indexNO), yhatNO_bertalanffy, col = "blue", lwd = 3)
lines(log(indexNO), yhatNO_brody, col = "green", lwd = 3)
lines(log(indexNO), yhatNO_monomolecular, col = "yellow", lwd = 3)
lines(log(indexNO), yhatNO_lima, col = "gray", lwd = 3)
indexNO <- seq(min(log(Hidroc$SIZE)),max(log(Hidroc$SIZE)),length.out=5000)
yhatNO_logistica <- 100/(1+exp(-result_logistica$par[1]*(indexNO- result_logistica$par[2])))
lines(indexNO, yhatNO_logistica, col = "purple", lwd = 3)


legend("bottomright",
       legend = c( 
           "Modelo Hill",
           "Modelo Bertalanffy",
           "Modelo Brody", 
           "Modelo Monomolecular",
           "Modelo Logística",
           "Modelo Lima"),
       col = c("red", "blue", "green", "yellow", "purple", "gray"),
       lwd = 3,
       bty = "n")




###################################### con ggplot


library(ggplot2)

# Crear dataframes para las líneas de ajuste (ajustar según los datos)
indexNO <- seq(min(Hidroc$SIZE), max(Hidroc$SIZE), length.out = 5000)
indexNO1 <- seq(min(log(Hidroc$SIZE)), max(log(Hidroc$SIZE)), length.out = 5000)

ggplot(Hidroc, aes(x = log(SIZE), y = Acum..Pasante)) +
    geom_point(aes(color = "Datos")) +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_hill, color = "Hill"), size = 1.5) +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_bertalanffy, color = "Bertalanffy"), size = 1.5) +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_brody, color = "Brody"), size = 1.5) +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_monomolecular, color = "Monomolecular"), size = 1.5) +
    geom_line(data = line_data, aes(x = indexNO1, y = yhatNO_logistica, color = "Logística"), size = 1.5) +
    geom_line(data = line_data, aes(x = log(indexNO), y = yhatNO_lima, color = "Lima"), size = 1.5) +
    
    labs(x = expression(paste("Granulometría [log(", mu, "m)]")), 
         y = "Acumulado Pasante", 
         title = "Ajuste de los modelos") +
    scale_color_manual(name = "Modelos",
                       values = c("Datos" = "black",
                                  "Bertalanffy" = "blue",
                                  "Brody" = "green",
                                  "Hill" = "red",
                                  "Lima" = "gray",
                                  "Logística" = "purple",
                                  "Monomolecular" = "yellow"),
                       breaks = c("Datos", "Bertalanffy", "Brody", "Hill", "Lima", "Logística", "Monomolecular")) +
    theme_minimal() +
    coord_cartesian(xlim = c(min(log(Hidroc$SIZE)), 7))  # Ajustar el límite del eje x


#######las verosimilitud de todos
result_bass$value
result_lima$value
result_monomolecular$value
result_brody$value
result_bertalanffy$value
result_hill$value
result_logistica$value
result_skaggs$value
result_fredlund$value
result_havercamp$value
result_morganetal$value
result_richards$value
result_Lweibull$value
result_Lgompertz$value
result_swebrec$value
result_gaudin_schuhmann$value
result_rossin_rammler$value
################ AIC

AIC_bass <- 2*result_bass$value+2*3
AIC_lima <- 2*result_lima$value+2*3
AIC_monomolecular <- 2*result_monomolecular$value+2*3
AIC_brody <- 2*result_brody$value+2*3
AIC_bertalanffy <- 2*result_bertalanffy$value+2*3
AIC_hill <- 2*result_hill$value+2*3
AIC_logistica <- 2*result_logistica$value+2*2
AIC_skaggs <- 2*result_skaggs$value+2*3
AIC_fredlund <- 2*result_fredlund$value+2*3
AIC_havercamp <- 2*result_havercamp$value+2*3
AIC_morganetal <- 2*result_morganetal$value+2*3
AIC_richards <- 2*result_richards$value+2*3
AIC_Lweibull <- 2*result_Lweibull$value+2*3
AIC_Lgompertz <- 2*result_Lgompertz$value+2*2
AIC_swebrec <- 2*result_swebrec$value+2*2
AIC_gaudin_schuhmann <- 2*result_gaudin_schuhmann$value+2*2
AIC_rossin_rammler <- 2*result_rossin_rammler$value+2*3

AIC_bass
AIC_monomolecular
AIC_brody
AIC_bertalanffy
AIC_hill
AIC_logistica
AIC_lima
AIC_skaggs
AIC_fredlund
AIC_havercamp
AIC_morganetal
AIC_richards
AIC_Lweibull
AIC_Lgompertz
AIC_swebrec
AIC_gaudin_schuhmann
AIC_rossin_rammler


# BIC
# BIC = k*ln(n) - 2ln(L) 
length(Hidroc$SIZE)

BIC_bass <- 2*result_bass$value+log(length(Hidroc$SIZE))*3
BIC_lima <- 2*result_lima$value+log(length(Hidroc$SIZE))*3
BIC_monomolecular <- 2*result_monomolecular$value+log(length(Hidroc$SIZE))*3
BIC_brody <- 2*result_brody$value+log(length(Hidroc$SIZE))*3
BIC_bertalanffy <- 2*result_bertalanffy$value+log(length(Hidroc$SIZE))*3
BIC_hill <- 2*result_hill$value+log(length(Hidroc$SIZE))*3
BIC_logistica <- 2*result_logistica$value+log(length(Hidroc$SIZE))*2
BIC_skaggs <- 2*result_skaggs$value+log(length(Hidroc$SIZE))*3
BIC_fredlund <- 2*result_fredlund$value+log(length(Hidroc$SIZE))*3
BIC_havercamp <- 2*result_havercamp$value+log(length(Hidroc$SIZE))*3
BIC_morganetal <- 2*result_morganetal$value+log(length(Hidroc$SIZE))*3
BIC_richards <- 2*result_richards$value+log(length(Hidroc$SIZE))*3
BIC_Lweibull <- 2*result_Lweibull$value+log(length(Hidroc$SIZE))*3
BIC_Lgompertz <- 2*result_Lgompertz$value+log(length(Hidroc$SIZE))*2
BIC_swebrec <- 2*result_swebrec$value+log(length(Hidroc$SIZE))*2
BIC_gaudin_schuhmann <- 2*result_gaudin_schuhmann$value+log(length(Hidroc$SIZE))*2
BIC_rossin_rammler <- 2*result_rossin_rammler$value+log(length(Hidroc$SIZE))*3

BIC_bass
BIC_monomolecular
BIC_brody
BIC_bertalanffy
BIC_hill
BIC_logistica
BIC_lima
BIC_skaggs
BIC_fredlund
BIC_havercamp
BIC_morganetal
BIC_richards
BIC_Lweibull
BIC_Lgompertz
BIC_swebrec
BIC_gaudin_schuhmann
BIC_rossin_rammler

##########################AICc
AICC_bass <-AIC_bass + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_lima <- AIC_lima + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_monomolecular <- AIC_monomolecular + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_brody <- AIC_brody + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_bertalanffy <- AIC_bertalanffy + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_hill <- AIC_hill + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_logistica <- AIC_logistica + 2*2*(2+1)/(length(Hidroc$SIZE)-2-1)
AICC_skaggs <- AIC_skaggs + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_fredlund <- AIC_fredlund + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_havercamp <- AIC_havercamp + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_morganetal <- AIC_morganetal + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_richards <- AIC_richards + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_Lweibull <- AIC_Lweibull + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)
AICC_Lgompertz <- AIC_Lgompertz + 2*2*(2+1)/(length(Hidroc$SIZE)-2-1)
AICC_swebrec <- AIC_swebrec + 2*2*(2+1)/(length(Hidroc$SIZE)-2-1)
AICC_gaudin_schuhmann <- AIC_gaudin_schuhmann + 2*2*(2+1)/(length(Hidroc$SIZE)-2-1)
AICC_rossin_rammler <- AIC_rossin_rammler + 2*3*(3+1)/(length(Hidroc$SIZE)-3-1)


AICC_bass
AICC_monomolecular
AICC_brody
AICC_bertalanffy
AICC_hill
AICC_logistica
AICC_lima
AICC_skaggs
AICC_fredlund
AICC_havercamp
AICC_morganetal
AICC_richards
AICC_Lweibull
AICC_Lgompertz
AICC_swebrec
AICC_gaudin_schuhmann
AICC_rossin_rammler

##################### Modelos mixtos #################
Se debe tener en cuenta que ya se cargo dados previamente 
y <- dados$Acum..Pasante
x <- dados$SIZE

## Despues de ejecutar el modelo de inferencia clasica en la seccicon inferencia clasica

AIC(modelo_inicial);BIC(modelo_inicial)


print(AIC);print(BIC)



xyplot(y ~ x | ID,  groups=ID, data=dados, main='Modelo Bertalanffy con efectos aleatorios',xlab = "Size", ylab = "Acumulado Pasante", pch = 16, 
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...);  # Plotando os pontos de observação
           y.prev <- y.prev[dados$ID == unique(dados$ID)[panel.number()]]
           #
           y.prev2 <- dados$mu[dados$ID == unique(dados$ID)[panel.number()]]
           #
           llines(x, y.prev, lwd = 2, col = 1);  # Plotando as curvas preditas
           panel.text(x = median(x)+50.2, y = median(y), labels = unique(dados$ID)[panel.number()], pos = 1, cex = 1.2);
       })   


# Distancias de Mahalanobis
u<-rep(1,(length(m)))
for (i in 1:(length(m))) u[i]<-
    switch(modelo,
           'normal'= t(y[s(i)] - ff[s(i)])%*% SigmaInv[s(i),s(i)] %*%(y[s(i)] - ff[s(i)]),
           't-Student' = t(y[s(i)] - ff[s(i)])%*% SigmaInv[s(i),s(i)] %*%(y[s(i)] - ff[s(i)]) / m[i]
    )

plot(u, pch=16, main = "M10 Mahalanobis distance")    
points(5, 119, col = "green", pch = 1, bg = "blue", cex = 3, lwd=3)  
points(1, 138, col = "green", pch = 1, bg = "blue", cex = 3, lwd =3)  


residuales <- c((y[s(1)] - ff[s(1)])%*%SigmaInv[s(1),s(1)],
                (y[s(2)] - ff[s(2)])%*%SigmaInv[s(2),s(2)],
                (y[s(3)] - ff[s(3)])%*%SigmaInv[s(3),s(3)],
                (y[s(4)] - ff[s(4)])%*%SigmaInv[s(4),s(4)],
                (y[s(5)] - ff[s(5)])%*%SigmaInv[s(5),s(5)],
                (y[s(6)] - ff[s(6)])%*%SigmaInv[s(6),s(6)],
                (y[s(7)] - ff[s(7)])%*%SigmaInv[s(7),s(7)],
                (y[s(8)] - ff[s(8)])%*%SigmaInv[s(8),s(8)],
                (y[s(9)] - ff[s(9)])%*%SigmaInv[s(9),s(9)],
                (y[s(10)] - ff[s(10)])%*%SigmaInv[s(10),s(10)],
                (y[s(11)] - ff[s(11)])%*%SigmaInv[s(11),s(11)],
                (y[s(12)] - ff[s(12)])%*%SigmaInv[s(12),s(12)],
                (y[s(13)] - ff[s(13)])%*%SigmaInv[s(13),s(13)],
                (y[s(14)] - ff[s(14)])%*%SigmaInv[s(14),s(14)],
                (y[s(15)] - ff[s(15)])%*%SigmaInv[s(15),s(15)])


hist(residuales)

plot(residuales, ylim = c(-2,2))







# VISUALIZATION
require(ggplot2)
p11=ggplot(ss, aes(x=residuales)) + geom_histogram() + coord_flip() + 
    scale_y_reverse()  + theme(
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

p12=ggplot(ss,aes(x=as.factor(X),y=residuales)) + 
    geom_violin(alpha=0.6) + xlab("Sample (unit)") + 
    ylab("Diff(Observed Sample, Estimated Model)") +
    stat_summary(fun = "median",col="red")+ 
    stat_summary(fun = "mean", col="blue")+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

cowplot::plot_grid(p11,p12,rel_heights = c(2,1),
                   rel_widths = c(1, 3))


ss <- dados
ss$residuales <-residuales

library(data.table)
setDT(ss)
DB1=dcast(ss, X ~ ID, value.var = "residuales")[,-1]

##--PARAMETRIC SPC--
require(qcc)
qcc.options(bg.margin = "white")

# Shewhart's (X-Bar and Range)
XbarChart = qcc(DB1, type = "xbar", center=0)
RChart = qcc(DB1, type = "R", center = 1.2, ylim =c(0, 2.5))

# 0 y 2.25

# CuSUM
CuSumChart <- cusum(DB1)
summary(CuSumChart)
# EWMA
EWMAChart <- ewma(DB1, lambda=0.2, nsigmas=3, ylim=c(-0.20,0.20))
summary(EWMAChart)


#################################### Inferencia Bayesiana #######################

# Echar primero a correr el codigo de inferencia bayesiana

################## logistico ############################

######################## Sin efecto aleatorio

fitlogistica <- stan(model_code = scode2, 
                     data = list(N=703, x=dados[,6], y=dados[,5]),
                     chain=4, iter=2000, verbose = FALSE)

print(fitlogistica)

elogistica <- extract(fitlogistica, permuted = FALSE)


log_lik_logistica=extract_log_lik(fitlogistica, merge_chains = FALSE)

loo_logistica <- loo(log_lik_logistica)
print(loo_logistica)

waic(log_lik_logistica)

######################### Con efecto aleatorio

fitlogistica2 <- stan(model_code = scode, 
                      data = list( N=703, x=dados[,6], y=dados[,5], id=as.integer(dados[,1]), 
                                   K=length(unique(dados[,1])) ),
                      chain=4, iter=2000, verbose = FALSE)


print(fitlogistica2)

log_lik_logistica2=extract_log_lik(fitlogistica2, merge_chains = FALSE)
waic(log_lik_logistica2)
loo_logistica2 <- loo(log_lik_logistica2)

print(loo_logistica2)

loo_compare(loo_logistica,loo_logistica2)

require(shinystan)
launch_shinystan(fit1)

## extract samples as a list of arrays
e2 <- extract(fit1, permuted = FALSE)

traceplot(fit1)

require(bayesplot)
mcmc_trace(fit1)

#################### Gaudin -schuhmann

######################## Sin efecto aleatorio

fitschuhmann <- stan(model_code = scodeschuhmann, 
                     data = list(N=703, x=dados[,4], y=dados[,5]),
                     chain=4, iter=2000, verbose = FALSE)
print(fitschuhmann)


log_lik_schuhmann=extract_log_lik(fitschuhmann, merge_chains = FALSE)

loo_schuhmann <- loo(log_lik_schuhmann)
print(loo_schuhmann)

# Con efecto aleatorio

fitschuhmann2 <- stan(model_code = scodeschuhmann2, 
                      data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                   K=length(unique(dados[,1])) ),
                      chain=4, iter=2000, verbose = FALSE)

print(fitschuhmann2)

log_lik_schuhmann2=extract_log_lik(fitschuhmann2, merge_chains = FALSE)

loo_schuhmann2 <- loo(log_lik_schuhmann2)
print(loo_schuhmann2)

############## Rosin-Rammler

######################## Sin efecto aleatorio

fitrosin <- stan(model_code = scoderosin, 
                 data = list(N=703, x=dados[,4], y=dados[,5]),
                 chain=4, iter=2000, verbose = FALSE)
print(fitrosin)

log_lik_rosin=extract_log_lik(fitrosin, merge_chains = FALSE)

loo_rosin <- loo(log_lik_rosin)
print(loo_rosin)


# Con efecto aleatorio

fitrosin2 <- stan(model_code = scoderosin2, 
                  data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                               K=length(unique(dados[,1])) ),
                  chain=4, iter=2000, verbose = FALSE)

log_lik_rosin2=extract_log_lik(fitrosin2, merge_chains = FALSE)

loo_rosin2 <- loo(log_lik_rosin2)
print(loo_rosin2)


########################## Weibull

######################## Sin efecto aleatorio

fitweibull <- stan(model_code = scodeweibull, 
                   data = list(N=703, x=dados[,4], y=dados[,5]),
                   chain=4, iter=2000, verbose = FALSE)
print(fitweibull)

log_lik_weibull=extract_log_lik(fitweibull, merge_chains = FALSE)

loo_weibull <- loo(log_lik_weibull)
print(loo_weibull)

# Con efecto aleatorio

fitweibull2 <- stan(model_code = scodeweibull2, 
                    data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                 K=length(unique(dados[,1])) ),
                    chain=4, iter=2000, verbose = FALSE)

log_lik_weibull2=extract_log_lik(fitweibull2, merge_chains = FALSE)

loo_weibull2 <- loo(log_lik_weibull2)
print(loo_weibull2)

########################## Gompertz

######################## Sin efecto aleatorio

fitgompertz <- stan(model_code = scodegompertz, 
                    data = list(N=703, x=dados[,4], y=dados[,5]),
                    chain=4, iter=2000, verbose = FALSE)
print(fitgompertz)

log_lik_gompertz=extract_log_lik(fitgompertz, merge_chains = FALSE)

loo_gompertz <- loo(log_lik_gompertz)
print(loo_gompertz)

# Con efecto aleatorio

fitgompertz2 <- stan(model_code = scodegompertz2, 
                     data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                  K=length(unique(dados[,1])) ),
                     chain=4, iter=2000, verbose = FALSE)

print(fitgompertz2)


log_lik_gompertz2=extract_log_lik(fitgompertz2, merge_chains = FALSE)

loo_gompertz2 <- loo(log_lik_gompertz2)
print(loo_gompertz2)

########################## Hill

######################## Sin efecto aleatorio

fithill <- stan(model_code = scodehill, 
                data = list(N=703, x=dados[,4], y=dados[,5]),
                chain=4, iter=2000, verbose = FALSE)
print(fithill)

log_lik_hill=extract_log_lik(fithill, merge_chains = FALSE)

loo_hill <- loo(log_lik_hill)
print(loo_hill)

######################### Con efecto aleatorio

fithill2 <- stan(model_code = scodehill2, 
                 data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                              K=length(unique(dados[,1])) ),
                 chain=4, iter=2000, verbose = FALSE)

print(fithill2)


log_lik_hill2=extract_log_lik(fithill2, merge_chains = FALSE)

loo_hill2 <- loo(log_lik_hill2)
print(loo_hill2)

########################## Bass

######################## Sin efecto aleatorio

fitbass <- stan(model_code = scodebass, 
                data = list(N=703, x=dados[,4], y=dados[,5]),
                chain=4, iter=2000, verbose = FALSE)
print(fitbass)

log_lik_bass=extract_log_lik(fitbass, merge_chains = FALSE)

loo_bass <- loo(log_lik_bass)
print(loo_bass)

# Con efecto aleatorio

fitbass2 <- stan(model_code = scodebass2, 
                 data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                              K=length(unique(dados[,1])) ),
                 chain=4, iter=2000, verbose = FALSE)

print(fitbass2)

log_lik_bass2=extract_log_lik(fitbass2, merge_chains = FALSE)

loo_bass2 <- loo(log_lik_bass2)
print(loo_bass2)

########################## Brody

######################## Sin efecto aleatorio

fitbrody <- stan(model_code = scodebrody, 
                 data = list(N=703, x=dados[,4], y=dados[,5]),
                 chain=4, iter=2000, verbose = FALSE)
print(fitbrody)

log_lik_brody=extract_log_lik(fitbrody, merge_chains = FALSE)

loo_brody <- loo(log_lik_brody)
print(loo_brody)

# Con efecto aleatorio

######################### Con efecto aleatorio

fitbrody2 <- stan(model_code = scodebrody2, 
                  data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                               K=length(unique(dados[,1])) ),
                  chain=4, iter=2000, verbose = FALSE)

print(fitbrody2)

log_lik_brody2=extract_log_lik(fitbrody2, merge_chains = FALSE)

loo_brody2 <- loo(log_lik_brody2)
print(loo_brody2)

########################## Bertalanffy

######################## Sin efecto aleatorio

fitbertalanffy <- stan(model_code = scodebertalanffy, 
                       data = list(N=703, x=dados[,4], y=dados[,5]),
                       chain=4, iter=2000, verbose = FALSE)
print(fitbertalanffy)

log_lik_bertalanffy=extract_log_lik(fitbertalanffy, merge_chains = FALSE)

loo_bertalanffy <- loo(log_lik_bertalanffy)
print(loo_bertalanffy)

# Con efecto aleatorio

fitbertalanffy2 <- stan(model_code = scodebertalanffy2, 
                        data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                     K=length(unique(dados[,1])) ),
                        chain=4, iter=2000, verbose = FALSE)

print(fitbertalanffy2)

log_lik_bertalanffy2=extract_log_lik(fitbertalanffy2, merge_chains = FALSE)

loo_bertalanffy2 <- loo(log_lik_bertalanffy2)
print(loo_bertalanffy2)

########################## Monomolecular

######################## Sin efecto aleatorio

fitmonomolecular <- stan(model_code = scodemonomolecular, 
                         data = list(N=703, x=dados[,4], y=dados[,5]),
                         chain=4, iter=2000, verbose = FALSE)
print(fitmonomolecular)

log_lik_monomolecular=extract_log_lik(fitmonomolecular, merge_chains = FALSE)

loo_monomolecular <- loo(log_lik_monomolecular)
print(loo_monomolecular)

# Con efecto aleatorio

fitmonomolecular2 <- stan(model_code = scodemonomolecular2, 
                          data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                       K=length(unique(dados[,1])) ),
                          chain=4, iter=2000, verbose = FALSE)

print(fitmonomolecular2)

log_lik_monomolecular2=extract_log_lik(fitmonomolecular2, merge_chains = FALSE)

loo_monomolecular2 <- loo(log_lik_monomolecular2)
print(loo_monomolecular2)

########################## Lima

######################## Sin efecto aleatorio

fitlima <- stan(model_code = scodelima, 
                data = list(N=703, x=dados[,4], y=dados[,5]),
                chain=4, iter=2000, verbose = FALSE)
print(fitlima)

log_lik_lima=extract_log_lik(fitlima, merge_chains = FALSE)

loo_lima <- loo(log_lik_lima)
print(loo_lima)

# Con efecto aleatorio

######################### Con efecto aleatorio

fitlima2 <- stan(model_code = scodelima2, 
                 data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                              K=length(unique(dados[,1])) ),
                 chain=4, iter=2000, verbose = FALSE)

print(fitlima2)

log_lik_lima2=extract_log_lik(fitlima2, merge_chains = FALSE)

loo_lima2 <- loo(log_lik_lima2)
print(loo_lima2)

########################## Skaggs

######################## Sin efecto aleatorio

fitskaggs <- stan(model_code = scodeskaggs, 
                  data = list(N=703, x=dados[,4], y=dados[,5]),
                  chain=4, iter=2000, verbose = FALSE)
print(fitskaggs)

log_lik_skaggs=extract_log_lik(fitskaggs, merge_chains = FALSE)

loo_skaggs <- loo(log_lik_skaggs)
print(loo_skaggs)

# Con efecto aleatorio

######################### Con efecto aleatorio

fitskaggs2 <- stan(model_code = scodeskaggs2, 
                   data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                K=length(unique(dados[,1])) ),
                   chain=4, iter=2000, verbose = FALSE)

print(fitskaggs2)

log_lik_skaggs2=extract_log_lik(fitskaggs2, merge_chains = FALSE)

loo_skaggs2 <- loo(log_lik_skaggs2)
print(loo_skaggs2)

########################## Fredlund

######################## Sin efecto aleatorio

fitfredlund <- stan(model_code = scodefredlund, 
                    data = list(N=703, x=dados[,4], y=dados[,5]),
                    chain=4, iter=2000, verbose = FALSE)
print(fitfredlund)

log_lik_fredlund=extract_log_lik(fitfredlund, merge_chains = FALSE)

loo_fredlund <- loo(log_lik_fredlund)
print(loo_fredlund)

# Con efecto aleatorio

######################### Con efecto aleatorio

fitfredlund2 <- stan(model_code = scodefredlund2, 
                     data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                  K=length(unique(dados[,1])) ),
                     chain=4, iter=2000, verbose = FALSE)

print(fitfredlund2)


log_lik_fredlund2=extract_log_lik(fitfredlund2, merge_chains = FALSE)

loo_fredlund2 <- loo(log_lik_fredlund2)
print(loo_fredlund2)

########################## Havercamp

######################## Sin efecto aleatorio

fithavercamp <- stan(model_code = scodehavercamp, 
                     data = list(N=703, x=dados[,4], y=dados[,5]),
                     chain=4, iter=2000, verbose = FALSE)
print(fithavercamp)

log_lik_havercamp=extract_log_lik(fithavercamp, merge_chains = FALSE)

loo_havercamp <- loo(log_lik_havercamp)
print(loo_havercamp)

# Con efecto aleatorio

fithavercamp2 <- stan(model_code = scodehavercamp2, 
                      data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                   K=length(unique(dados[,1])) ),
                      chain=4, iter=2000, verbose = FALSE)

print(fithavercamp2)

log_lik_havercamp2=extract_log_lik(fithavercamp2, merge_chains = FALSE)

loo_havercamp2 <- loo(log_lik_havercamp2)
print(loo_havercamp2)

########################## Morganetal

######################## Sin efecto aleatorio

fitmorganetal <- stan(model_code = scodemorganetal, 
                      data = list(N=703, x=dados[,4], y=dados[,5]),
                      chain=4, iter=2000, verbose = FALSE)
print(fitmorganetal)

log_lik_morganetal=extract_log_lik(fitmorganetal, merge_chains = FALSE)

loo_morganetal <- loo(log_lik_morganetal)
print(loo_morganetal)

# Con efecto aleatorio

fitmorganetal2 <- stan(model_code = scodemorganetal2, 
                       data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                    K=length(unique(dados[,1])) ),
                       chain=4, iter=2000, verbose = FALSE)

print(fitmorganetal2)


log_lik_morganetal2=extract_log_lik(fitmorganetal2, merge_chains = FALSE)

loo_morganetal2 <- loo(log_lik_morganetal2)
print(loo_morganetal2)

########################## Richards

######################## Sin efecto aleatorio
fitrichards <- stan(model_code = scoderichards, 
                    data = list(N=703, x=dados[,4], y=dados[,5]),
                    chain=4, iter=2000, verbose = FALSE)
print(fitrichards)

log_lik_richards=extract_log_lik(fitrichards, merge_chains = FALSE)

loo_richards <- loo(log_lik_richards)
print(loo_richards)

# Con efecto aleatorio

fitrichards2 <- stan(model_code = scoderichards2, 
                     data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                  K=length(unique(dados[,1])) ),
                     chain=4, iter=2000, verbose = FALSE)

print(fitrichards2)


log_lik_richards2=extract_log_lik(fitrichards2, merge_chains = FALSE)

loo_richards2 <- loo(log_lik_richards2)
print(loo_richards2)

########################## Swebrec
######################## Sin efecto aleatorio

fitswebrec <- stan(model_code = scodeswebrec, 
                   data = list(N=703, x=dados[,4], y=dados[,5]),
                   chain=4, iter=2000, verbose = FALSE)
print(fitswebrec)

log_lik_swebrec=extract_log_lik(fitswebrec, merge_chains = FALSE)

loo_swebrec <- loo(log_lik_swebrec)
print(loo_swebrec)

# Con efecto aleatorio

fitswebrec2 <- stan(model_code = scodeswebrec2, 
                    data = list( N=703, x=dados[,4], y=dados[,5], id=as.integer(dados[,1]), 
                                 K=length(unique(dados[,1])) ),
                    chain=4, iter=2000, verbose = FALSE)

print(fitswebrec2)


log_lik_swebrec2=extract_log_lik(fitswebrec2, merge_chains = FALSE)

loo_swebrec2 <- loo(log_lik_swebrec2)
print(loo_swebrec2)

####################################################

loo_compare(loo_logistica,loo_schuhmann,loo_rosin,loo_weibull,
            loo_gompertz,loo_hill,loo_bass,loo_brody,loo_bertalanffy
            ,loo_monomolecular,loo_lima,loo_skaggs,loo_fredlund
            ,loo_havercamp,loo_morganetal,loo_richards,loo_swebrec)

# bertalanffy
# lima
# rosin
# weibull
# skaggs
# havecamp

loo_compare(loo_logistica2,loo_schuhmann2,loo_rosin2,loo_weibull2,
            loo_gompertz2,loo_hill2,loo_bass2,loo_brody2,loo_bertalanffy2
            ,loo_monomolecular2,loo_lima2,loo_skaggs2,loo_fredlund2
            ,loo_havercamp2,loo_morganetal2,loo_richards2,loo_swebrec2)

# TODOS (TOP 5)
loo_compare(loo_logistica, # 1
            loo_schuhmann, # 2
            loo_rosin, # 3
            loo_weibull, # 4
            loo_gompertz, # 5
            loo_hill, # 6
            loo_bass, # 7
            loo_brody, #8
            loo_bertalanffy, # 9
            loo_monomolecular, # 10
            loo_lima, # 11
            loo_skaggs, # 12
            loo_fredlund, # 13
            loo_havercamp, # 14
            loo_morganetal, # 15
            loo_richards, # 16
            loo_swebrec, # 17
            loo_logistica2, # 18
            loo_schuhmann2, # 19
            loo_rosin2, # 20
            loo_weibull2, # 21
            loo_gompertz2, # 22
            loo_hill2, # 23
            loo_bass2, # 24
            loo_brody2, # 25
            loo_bertalanffy2, # 26
            loo_monomolecular2, # 27
            loo_lima2, # 28
            loo_skaggs2, # 29
            loo_fredlund2, # 30
            loo_havercamp2, # 31
            loo_morganetal2, # 32
            loo_richards2, # 33
            loo_swebrec2) # 34

loo_compare(
    waic(log_lik_logistica),# 1
    waic(log_lik_logistica2),# 2
    waic(log_lik_bass),# 3
    waic(log_lik_bass2),# 4
    waic(log_lik_bertalanffy), # 5
    waic(log_lik_bertalanffy2), # 6
    waic(log_lik_brody), # 7
    waic(log_lik_brody2), # 8
    waic(log_lik_fredlund), # 9
    waic(log_lik_fredlund2), # 10
    waic(log_lik_gompertz), # 11
    waic(log_lik_gompertz2), # 12
    waic(log_lik_havercamp), # 13
    waic(log_lik_havercamp2), # 14
    waic(log_lik_hill), # 15
    waic(log_lik_hill2), # 16
    waic(log_lik_lima), # 17
    waic(log_lik_lima2), # 18
    waic(log_lik_monomolecular), # 19
    waic(log_lik_monomolecular2), # 20
    waic(log_lik_morganetal), # 21
    waic(log_lik_morganetal2), # 22
    waic(log_lik_richards), # 23
    waic(log_lik_richards2), # 24
    waic(log_lik_rosin), # 25
    waic(log_lik_rosin2), # 26
    waic(log_lik_schuhmann), # 27
    waic(log_lik_schuhmann2), # 28
    waic(log_lik_skaggs), # 29
    waic(log_lik_skaggs2), # 30
    waic(log_lik_swebrec), # 31
    waic(log_lik_swebrec2), # 32
    waic(log_lik_weibull), # 33
    waic(log_lik_weibull2) # 34
)

#### WAIC

loo(log_lik_logistica)$looic; waic(log_lik_logistica)$waic
loo(log_lik_logistica2)$looic; waic(log_lik_logistica2)$waic

loo(log_lik_bass)$looic; waic(log_lik_bass)$waic
loo(log_lik_bass2)$looic; waic(log_lik_bass2)$waic

loo(log_lik_bertalanffy)$looic; waic(log_lik_bertalanffy)$waic
loo(log_lik_bertalanffy2)$looic; waic(log_lik_bertalanffy2)$waic

loo(log_lik_brody)$looic; waic(log_lik_brody)$waic
loo(log_lik_brody2)$looic; waic(log_lik_brody2)$waic

loo(log_lik_fredlund)$looic; waic(log_lik_fredlund)$waic
loo(log_lik_fredlund2)$looic; waic(log_lik_fredlund2)$waic

loo(log_lik_gompertz)$looic; waic(log_lik_gompertz)$waic
loo(log_lik_gompertz2)$looic; waic(log_lik_gompertz2)$waic

loo(log_lik_havercamp)$looic; waic(log_lik_havercamp)$waic
loo(log_lik_havercamp2)$looic; waic(log_lik_havercamp2)$waic

loo(log_lik_hill)$looic; waic(log_lik_hill)$waic
loo(log_lik_hill2)$looic; waic(log_lik_hill2)$waic

loo(log_lik_lima)$looic; waic(log_lik_lima)$waic
loo(log_lik_lima2)$looic; waic(log_lik_lima2)$waic

loo(log_lik_monomolecular)$looic; waic(log_lik_monomolecular)$waic
loo(log_lik_monomolecular2)$looic; waic(log_lik_monomolecular2)$waic

loo(log_lik_morganetal)$looic; waic(log_lik_morganetal)$waic
loo(log_lik_morganetal2)$looic; waic(log_lik_morganetal2)$waic

loo(log_lik_richards)$looic; waic(log_lik_richards)$waic
loo(log_lik_richards2)$looic; waic(log_lik_richards2)$waic

loo(log_lik_rosin)$looic; waic(log_lik_rosin)$waic
loo(log_lik_rosin2)$looic; waic(log_lik_rosin2)$waic

loo(log_lik_schuhmann)$looic; waic(log_lik_schuhmann)$waic
loo(log_lik_schuhmann2)$looic; waic(log_lik_schuhmann2)$waic

loo(log_lik_skaggs)$looic; waic(log_lik_skaggs)$waic
loo(log_lik_skaggs2)$looic; waic(log_lik_skaggs2)$waic

loo(log_lik_swebrec)$looic; waic(log_lik_swebrec)$waic
loo(log_lik_swebrec2)$looic; waic(log_lik_swebrec2)$waic

loo(log_lik_weibull)$looic; waic(log_lik_weibull)$waic
loo(log_lik_weibull2)$looic; waic(log_lik_weibull2)$waic

#####################################
library(rstan)
library(dplyr)

a <- extract(fitbertalanffy2)
vector_mu <- as.vector(a$mu)

promedios <- tapply(vector_mu, (seq_along(vector_mu) - 1) %/% 4000, mean)
promedios <- as.vector(promedios)
length(promedios)
dados <- dados %>%
    mutate(mu = promedios)


xyplot(Y ~ X | ID,  groups=ID, data=dados, main='Modelo Bertalanffy con efectos aleatorios',xlab = "Size", ylab = "Acumulado Pasante", pch = 16, 
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...);  # Plotando os pontos de observação
           y.prev <- dados$mu[dados$ID == unique(dados$ID)[panel.number()]]
           llines(x, y.prev, lwd = 2, col = 1);  # Plotando as curvas preditas
           panel.text(x = median(x)+50.2, y = median(y), labels = unique(dados$ID)[panel.number()], pos = 1, cex = 1.2);
       })  

b <- extract(fithavercamp2)
mean(a$beta0)
vector_mu <- as.vector(b$mu)

promedios <- tapply(vector_mu, (seq_along(vector_mu) - 1) %/% 4000, mean)
promedios <- as.vector(promedios)
length(promedios)
dados <- dados %>%
    mutate(mu = promedios)

xyplot(Y ~ X | ID,  groups=ID, data=dados, main='Modelo Havercamp con efectos aleatorios',xlab = "Size", ylab = "Acumulado Pasante", pch = 16, 
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...);  # Plotando os pontos de observação
           y.prev <- dados$mu[dados$ID == unique(dados$ID)[panel.number()]]
           llines(x, y.prev, lwd = 2, col = 1);  # Plotando as curvas preditas
           panel.text(x = median(x)+50.2, y = median(y), labels = unique(dados$ID)[panel.number()], pos = 1, cex = 1.2);
       })   
